---
title: "5 Whys na PrÃ¡tica: Encontrando a Causa Raiz Sem Perder a Sanidade"
date: 2025-01-07
draft: false
categories: ["SRE", "DevOps", "GestÃ£o de Incidentes"]
tags: ["5-whys", "root-cause-analysis", "RCA", "post-mortem", "incidentes", "troubleshooting"]
---

A tÃ©cnica dos 5 Whys Ã© como bisturi na mÃ£o de cirurgiÃ£o: poderosa quando bem usada, desastrosa quando nÃ£o. Depois de facilitar dezenas de sessÃµes de RCA (Root Cause Analysis), vi de tudo: desde anÃ¡lises brilhantes que preveniram desastres futuros atÃ© sessÃµes que viraram caÃ§a Ã s bruxas ou, pior ainda, teatro corporativo. Vamos ao que realmente funciona.

## O Problema com os 5 Whys Tradicionais

A tÃ©cnica, criada pela Toyota, parece simples: pergunte "por quÃª?" cinco vezes e chegue Ã  causa raiz. Na prÃ¡tica, Ã© como dizer que para ser rico basta comprar na baixa e vender na alta - tecnicamente correto, praticamente inÃºtil sem contexto.

**Exemplo clÃ¡ssico (e inÃºtil)**:
```
Problema: Site fora do ar
Por quÃª? Servidor web parou
Por quÃª? Ficou sem memÃ³ria  
Por quÃª? Memory leak no cÃ³digo
Por quÃª? Desenvolvedor nÃ£o testou direito
Por quÃª? Estava com pressa
```

ParabÃ©ns, vocÃª acabou de culpar o JoÃ£o e nÃ£o resolveu nada. 

## 5 Whys que Funcionam: Casos Reais

### Caso 1: O MistÃ©rio dos Uploads Fantasmas

**Contexto**: Sistema de upload de documentos falhando aleatoriamente Ã s terÃ§as-feiras.

**InvestigaÃ§Ã£o**:
```yaml
Problema: Uploads falham Ã s terÃ§as, ~14h
â†“ Por quÃª?
API retorna timeout apÃ³s 30 segundos
â†“ Por quÃª?
Processo de vÃ­rus scan demora mais que o normal
â†“ Por quÃª? 
Base de assinaturas de vÃ­rus muito grande Ã s terÃ§as
â†“ Por quÃª?
Update semanal de assinaturas acontece terÃ§a 13h30
â†“ Por quÃª?
Cron foi configurado em UTC, nÃ£o em horÃ¡rio local
```

**Causa Raiz Real**: Problema de timezone, nÃ£o de performance.

**AÃ§Ãµes**:
1. Ajustar cron para horÃ¡rio de menor uso (madrugada)
2. Implementar cache de assinaturas jÃ¡ verificadas
3. Alertas para degradaÃ§Ã£o de performance em uploads

### Caso 2: Database Connection Pool do Inferno

**Contexto**: AplicaÃ§Ã£o comeÃ§ou a ter spikes de latÃªncia apÃ³s deploy "sem mudanÃ§as".

```yaml
Problema: LatÃªncia de 5s em requests que eram 200ms
â†“ Por quÃª?
Connections com DB demoram para ser estabelecidas
â†“ Por quÃª?
Pool de conexÃµes estÃ¡ sempre vazio
â†“ Por quÃª?
Health check fecha conexÃµes apÃ³s teste
â†“ Por quÃª?
Nova lib de health check nÃ£o reutiliza conexÃµes do pool
â†“ Por quÃª?
Dev copiou exemplo da doc sem adaptar ao nosso contexto
```

**Plot Twist**: O "deploy sem mudanÃ§as" atualizou dependÃªncias transitivas.

**AÃ§Ãµes**:
1. Lock de versÃµes em dependÃªncias crÃ­ticas
2. Health check com conexÃ£o dedicada fora do pool
3. MÃ©tricas de utilizaÃ§Ã£o do connection pool

### Caso 3: O Paradoxo do Cache Perfeito

**Contexto**: Sistema mais lento DEPOIS de implementar cache.

```yaml
Problema: API 3x mais lenta com cache Redis
â†“ Por quÃª?
Cada request faz mÃºltiplas chamadas ao Redis
â†“ Por quÃª?
Cache granular demais (1 key por campo)
â†“ Por quÃª?
ImplementaÃ§Ã£o seguiu pattern de ORM cegamente
â†“ Por quÃª?
Arquiteto definiu "cache em todas as camadas"
â†“ Por quÃª?
Trauma de incidente anterior sem cache
```

**LiÃ§Ã£o**: Ã€s vezes a causa raiz Ã© overcorrection de problema passado.

## Quando Parar de Perguntar "Por QuÃª?"

A regra dos "5" Ã© arbitrÃ¡ria. O segredo Ã© parar quando vocÃª chega em uma das seguintes situaÃ§Ãµes:

### 1. AÃ§Ã£o Concreta PossÃ­vel
Se vocÃª pode fazer algo especÃ­fico para prevenir o problema, pare.

**Bom**: "Config de timeout muito baixo" â†’ Aumentar timeout
**Ruim**: "Cultura da empresa" â†’ ???

### 2. Limite de Controle
Quando sai da sua esfera de influÃªncia, documente mas nÃ£o continue.

**Exemplo**: 
```yaml
Por quÃª AWS teve outage?
â†’ Problema no datacenter deles
â†’ PARE. VocÃª nÃ£o vai consertar a AWS.
```

### 3. Loop Circular
Se as respostas comeÃ§am a se repetir, vocÃª foi longe demais.

```yaml
Por quÃª nÃ£o temos testes?
â†’ NÃ£o temos tempo
Por quÃª nÃ£o temos tempo?
â†’ Muitos bugs para corrigir
Por quÃª muitos bugs?
â†’ NÃ£o temos testes
â†’ ğŸ”„ LOOP DETECTADO
```

## Como Evitar AnÃ¡lises Superficiais

### 1. Use Dados, NÃ£o OpiniÃµes

**Superficial**: "O deploy causou o problema"
**Profundo**: "Commit abc123 introduziu query N+1 que aparece no slow query log"

### 2. Diversifique os "Por QuÃªs"

NÃ£o use apenas "Por quÃª?". Varie:
- "O que mudou?"
- "Quando comeÃ§ou?"
- "Onde mais isso acontece?"
- "Como sabemos disso?"
- "Quem mais foi impactado?"

### 3. Timeline Reversa

Comece do momento da detecÃ§Ã£o e vÃ¡ voltando:
```
14:32 - Alerta disparou
14:30 - Erro rate subiu para 15%
14:28 - Deploy em produÃ§Ã£o
14:15 - PR merged sem aprovaÃ§Ã£o
13:45 - Tests desabilitados "temporariamente"
```

### 4. Embrace o "NÃ£o Sei"

Melhor admitir ignorÃ¢ncia do que inventar causa:

```yaml
Por quÃª memory leak aconteceu?
â†’ NÃ£o sabemos ainda, precisamos de:
  - Memory profiler em produÃ§Ã£o
  - Heap dumps do momento do problema
  - Reproduzir em ambiente controlado
```

## Exemplos de RCA Bem Documentado

### Template que Funciona

```markdown
# RCA: Outage Sistema de Pagamentos - 2024-03-15

## Impacto
- DuraÃ§Ã£o: 45 minutos (14:00 - 14:45 UTC)
- Clientes afetados: ~15.000
- TransaÃ§Ãµes perdidas: 0 (todas foram enfileiradas)
- Impacto financeiro: R$ 45.000 em vendas atrasadas

## Timeline
14:00 - Deploy automÃ¡tico apÃ³s merge
14:02 - Primeiros timeouts em logs
14:05 - Alerta de latÃªncia disparou
14:08 - Equipe iniciou investigaÃ§Ã£o
14:15 - Identificado lock em tabela
14:20 - Rollback iniciado
14:30 - Sistema restaurado
14:45 - Backlog processado

## AnÃ¡lise 5 Whys

Problema: Todas transaÃ§Ãµes travaram por 45min
â†“ Por quÃª?
Lock exclusivo na tabela de transaÃ§Ãµes
â†“ Por quÃª?
Migration rodou ALTER TABLE em produÃ§Ã£o
â†“ Por quÃª?
Deploy incluiu migration nÃ£o revisada
â†“ Por quÃª?
CI/CD nÃ£o diferencia migrations perigosas
â†“ Por quÃª?
Assumimos que todas migrations sÃ£o safe

## Causa Raiz
Migration com ALTER TABLE bloqueante em tabela crÃ­tica foi executada automaticamente em horÃ¡rio de pico.

## AÃ§Ãµes
1. [P0] Migrations com ALTER TABLE requerem aprovaÃ§Ã£o manual
2. [P0] Implementar pt-online-schema-change para alteraÃ§Ãµes
3. [P1] Alertas para locks longos em tabelas crÃ­ticas
4. [P1] Runbook para situaÃ§Ãµes de lock
5. [P2] Workshop sobre migrations safe para todo time

## LiÃ§Ãµes Aprendidas
- Nem toda migration Ã© criada igual
- Ferramentas de schema change online sÃ£o essenciais
- AutomaÃ§Ã£o sem safeguards Ã© uma arma carregada
```

## Como Compartilhar Aprendizados

### 1. RCA Lightning Talks
5 minutos, 3 slides:
- O que aconteceu
- Por que aconteceu  
- O que fizemos para nunca mais acontecer

### 2. Failure Friday
SessÃ£o mensal onde times compartilham suas "melhores" falhas. Regras:
- Sem julgamentos
- Foco no aprendizado
- PrÃªmio para "Falha Mais Educativa"

### 3. Runbook Wiki
Cada RCA vira um runbook:
```markdown
## Se vocÃª ver: "Lock wait timeout exceeded"

### DiagnÃ³stico RÃ¡pido
```sql
SHOW PROCESSLIST;
SELECT * FROM information_schema.innodb_locks;
```

### AÃ§Ã£o Imediata
1. Identificar query bloqueante
2. Se migration: KILL <process_id>
3. Se transaÃ§Ã£o business: escalar para produto

### PrevenÃ§Ã£o
- Sempre use pt-online-schema-change
- Rode migrations fora do horÃ¡rio de pico
- Teste em staging com dados reais
```

## Armadilhas Comuns e Como Evitar

### 1. A Culpa Ã© do EstagiÃ¡rio
Se seu 5 Whys sempre termina em "erro humano", vocÃª estÃ¡ fazendo errado.

**Errado**: "JoÃ£o nÃ£o testou"
**Certo**: "Nosso processo permite deploy sem testes"

### 2. Paralisia por AnÃ¡lise
NÃ£o precisa entender fÃ­sica quÃ¢ntica para consertar um bug.

**PragmÃ¡tico**: Pare quando tiver aÃ§Ã£o clara
**AcadÃªmico**: Continue atÃ© entender o universo

### 3. RCA Como PuniÃ§Ã£o
Se RCA vira tribunal, pessoas param de reportar problemas.

**Criar**: Ambiente de aprendizado
**Evitar**: CaÃ§a Ã s bruxas

## Ferramentas que Facilitam

### Para Coleta de EvidÃªncias
```bash
# Script que rodo assim que incidente comeÃ§a
#!/bin/bash
INCIDENT_DIR="incident-$(date +%Y%m%d-%H%M%S)"
mkdir $INCIDENT_DIR
kubectl logs -n prod --tail=1000 > $INCIDENT_DIR/k8s-logs.txt
pg_dump -s > $INCIDENT_DIR/db-schema.sql
curl http://metrics/api/snapshot > $INCIDENT_DIR/metrics.json
git log --oneline -20 > $INCIDENT_DIR/recent-commits.txt
```

### Para VisualizaÃ§Ã£o
- **Mermaid**: Para diagramas de sequÃªncia
- **draw.io**: Para diagramas de arquitetura
- **Grafana**: Para correlacionar mÃ©tricas com eventos

## ConclusÃ£o: RCA Ã© Sobre o Futuro, NÃ£o o Passado

O objetivo do 5 Whys nÃ£o Ã© encontrar culpados ou provar que vocÃª Ã© o Sherlock Holmes da engenharia. Ã‰ sobre prevenir que o mesmo problema aconteÃ§a novamente.

Uma boa anÃ¡lise de causa raiz:
- Foca em sistemas, nÃ£o pessoas
- Busca mÃºltiplas causas contribuintes
- PropÃµe aÃ§Ãµes concretas e mensurÃ¡veis
- Ã‰ compartilhada amplamente
- Vira conhecimento institucional

Se seu 5 Whys nÃ£o estÃ¡ gerando mudanÃ§as reais, vocÃª estÃ¡ apenas fazendo teatro. E se estÃ¡ virando sessÃ£o de apontar dedos, estÃ¡ na hora de repensar sua cultura.

Lembre-se: todo sistema complexo falha de formas complexas. A arte estÃ¡ em aprender com cada falha sem perder a sanidade no processo.

---

*No final, a melhor pergunta nÃ£o Ã© "por que isso aconteceu?" mas sim "o que podemos fazer para que seja impossÃ­vel acontecer de novo?". Essa mudanÃ§a de perspectiva transforma post-mortems de autÃ³psias em sessÃµes de fortalecimento do sistema.*